{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to backtracking search...\n",
      "Costas permutation for N=15:\n",
      "[ 1  2  6 14  9  3 15 13  5 10 12 11  8  4  7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from costas import generate_costas_array, visualize_costas_array\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    N = 15  # Change to desired size\n",
    "    result = generate_costas_array(N)\n",
    "    if result is not None:\n",
    "        print(f\"Costas permutation for N={N}:\")\n",
    "        print(result + 1)  # Convert 0-based to 1-based indexing\n",
    "    visualize_costas_array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss = 1.1683\n",
      "Epoch 20/200, Loss = 0.9305\n",
      "Epoch 30/200, Loss = 0.8549\n",
      "Epoch 40/200, Loss = 0.8188\n",
      "Epoch 50/200, Loss = 0.8006\n",
      "Epoch 60/200, Loss = 0.7947\n",
      "Epoch 70/200, Loss = 0.7930\n",
      "Epoch 80/200, Loss = 0.7925\n",
      "Epoch 90/200, Loss = 0.7924\n",
      "Epoch 100/200, Loss = 0.7920\n",
      "Epoch 110/200, Loss = 0.7913\n",
      "Epoch 120/200, Loss = 0.7913\n",
      "Epoch 130/200, Loss = 0.7912\n",
      "Epoch 140/200, Loss = 0.7912\n",
      "Epoch 150/200, Loss = 0.7911\n",
      "Epoch 160/200, Loss = 0.7911\n",
      "Epoch 170/200, Loss = 0.7909\n",
      "Epoch 180/200, Loss = 0.7906\n",
      "Epoch 190/200, Loss = 0.7905\n",
      "Epoch 200/200, Loss = 0.7904\n",
      "\n",
      "Neural-Net-Stitched Permutation (0-based columns):\n",
      "[ 1 20 29 14  0  6 13  2 18 14  8 21 15  6 27  9  0 22  1  2 25 29 13 17\n",
      " 28  0 25 12  0  2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Existing Costas-Array Code (as provided)\n",
    "# -------------------------------------------------------------------------\n",
    "@njit\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n % 2 == 0:\n",
    "        return n == 2\n",
    "    for x in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % x == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "@njit\n",
    "def powmod(base, exp, mod):\n",
    "    result = 1\n",
    "    while exp > 0:\n",
    "        if exp & 1:\n",
    "            result = (result * base) % mod\n",
    "        base = (base * base) % mod\n",
    "        exp >>= 1\n",
    "    return result\n",
    "\n",
    "@njit\n",
    "def find_primitive_root(p):\n",
    "    phi = p - 1\n",
    "    factors = []\n",
    "    temp = phi\n",
    "    for f in range(2, int(temp**0.5) + 1):\n",
    "        if temp % f == 0:\n",
    "            factors.append(f)\n",
    "            while temp % f == 0:\n",
    "                temp //= f\n",
    "    if temp > 1:\n",
    "        factors.append(temp)\n",
    "\n",
    "    for g in range(2, p):\n",
    "        for factor in factors:\n",
    "            if powmod(g, phi // factor, p) == 1:\n",
    "                break\n",
    "        else:\n",
    "            return g\n",
    "    return -1\n",
    "\n",
    "@njit\n",
    "def welch_costas(n):\n",
    "    \"\"\" Returns a permutation of size n if n+1 is prime; else None. \"\"\"\n",
    "    p = n + 1\n",
    "    if not is_prime(p):\n",
    "        return None\n",
    "    g = find_primitive_root(p)\n",
    "    if g < 0:\n",
    "        return None\n",
    "    perm = np.empty(n, dtype=np.int64)\n",
    "    cur = 1\n",
    "    for i in range(n):\n",
    "        cur = (cur * g) % p\n",
    "        perm[i] = cur - 1\n",
    "    return perm\n",
    "\n",
    "@njit\n",
    "def _search_costas(permutation, used_col, used_diffs, row, N):\n",
    "    if row == N:\n",
    "        return True\n",
    "    for col in range(N):\n",
    "        if not used_col[col]:\n",
    "            valid = True\n",
    "            for rprev in range(row):\n",
    "                rdiff = row - rprev\n",
    "                cdiff = col - permutation[rprev] + N - 1\n",
    "                if used_diffs[rdiff, cdiff]:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if valid:\n",
    "                permutation[row] = col\n",
    "                used_col[col] = True\n",
    "                for rprev in range(row):\n",
    "                    rdiff = row - rprev\n",
    "                    cdiff = col - permutation[rprev] + N - 1\n",
    "                    used_diffs[rdiff, cdiff] = True\n",
    "\n",
    "                if _search_costas(permutation, used_col, used_diffs, row + 1, N):\n",
    "                    return True\n",
    "\n",
    "                used_col[col] = False\n",
    "                for rprev in range(row):\n",
    "                    rdiff = row - rprev\n",
    "                    cdiff = col - permutation[rprev] + N - 1\n",
    "                    used_diffs[rdiff, cdiff] = False\n",
    "    return False\n",
    "\n",
    "@njit\n",
    "def costas_array_backtracking(N):\n",
    "    if N == 1:\n",
    "        return np.array([0], dtype=np.int64)\n",
    "    permutation = np.full(N, -1, dtype=np.int64)\n",
    "    used_col = np.zeros(N, dtype=np.bool_)\n",
    "    used_diffs = np.zeros((N, 2*N - 1), dtype=np.bool_)\n",
    "    if _search_costas(permutation, used_col, used_diffs, 0, N):\n",
    "        return permutation\n",
    "    return None\n",
    "\n",
    "@njit\n",
    "def generate_costas_array_njit(N):\n",
    "    if N < 1:\n",
    "        return None\n",
    "    permutation = welch_costas(N)\n",
    "    if permutation is not None:\n",
    "        return permutation\n",
    "    # fallback\n",
    "    return costas_array_backtracking(N)\n",
    "\n",
    "def generate_costas_array(N):\n",
    "    result = generate_costas_array_njit(N)\n",
    "    if result is not None:\n",
    "        if welch_costas(N) is not None:\n",
    "            print(\"Generated using Welch method.\")\n",
    "        else:\n",
    "            print(\"Falling back to backtracking search...\")\n",
    "    return result\n",
    "\n",
    "def visualize_costas_array(permutation):\n",
    "    if permutation is None:\n",
    "        print(\"No Costas array to display.\")\n",
    "        return\n",
    "    N = len(permutation)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(np.arange(N) + 0.5, permutation + 0.5, color='blue', s=100 / N)\n",
    "    plt.xlim(0, N)\n",
    "    plt.ylim(0, N)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Costas Array (N={N})\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. \"Prime Factor + Neural Network\" Attempt\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def factor_int(n):\n",
    "    \"\"\"Naive integer factorization (for demonstration).\"\"\"\n",
    "    # In practice, you might call a better factorization or Shor's algorithm\n",
    "    factors = []\n",
    "    # Check divisibility by 2\n",
    "    while n % 2 == 0:\n",
    "        factors.append(2)\n",
    "        n //= 2\n",
    "    # Check odd factors\n",
    "    f = 3\n",
    "    while f * f <= n:\n",
    "        while n % f == 0:\n",
    "            factors.append(f)\n",
    "            n //= f\n",
    "        f += 2\n",
    "    if n > 1:\n",
    "        factors.append(n)\n",
    "    return factors\n",
    "\n",
    "def get_subarrays_from_prime_factors(n):\n",
    "    \"\"\"Generate Welch Costas arrays for each prime factor p => p-1.\"\"\"\n",
    "    factors = factor_int(n)\n",
    "    sub_arrays = []\n",
    "    for p in factors:\n",
    "        sub_n = p - 1\n",
    "        wc = welch_costas(sub_n)\n",
    "        if wc is not None:\n",
    "            sub_arrays.append(wc)\n",
    "        else:\n",
    "            # Could fallback to backtracking or skip\n",
    "            sub_arrays.append(np.array([], dtype=np.int64))\n",
    "    return sub_arrays\n",
    "\n",
    "# -- Simple MLP to try to form an Nx array from prime-based subarrays --\n",
    "class StitcherNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, N):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # We'll produce a \"logit\" for each row, for each possible column\n",
    "        # e.g. output shape (N, N), then we pick an argmax in each row\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, N*N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, input_dim)\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        out = self.fc2(h)  # shape: (batch_size, N*N)\n",
    "        # We can reshape to (batch_size, N, N)\n",
    "        out = out.view(-1, self.N, self.N)\n",
    "        return out\n",
    "\n",
    "def costas_loss(pred_array):\n",
    "    \"\"\"\n",
    "    A 'soft' loss that penalizes repeated differences.\n",
    "    pred_array: shape (batch, N, N).\n",
    "      We'll interpret row i's distribution as which column is chosen.\n",
    "      We'll do a \"soft\" argmax with row i's distribution.\n",
    "    This is purely a demonstrationâ€” discrete constraints are tricky.\n",
    "    \"\"\"\n",
    "    batch_size, N, _ = pred_array.shape\n",
    "\n",
    "    # Convert row distributions into a 'column index' in a differentiable way,\n",
    "    # e.g. softmax -> column \"probabilities\"\n",
    "    row_probs = torch.softmax(pred_array, dim=2)  # shape (batch, N, N)\n",
    "\n",
    "    # We can sample or do an expected dot. We'll do an \"expected column index\"\n",
    "    columns = torch.arange(N).to(pred_array.device)\n",
    "    # shape: (N)\n",
    "    # shape after unsqueeze & broadcast => (1, 1, N)\n",
    "    col_indices = (row_probs * columns.unsqueeze(0).unsqueeze(0)).sum(dim=2)\n",
    "    # shape: (batch, N) is the \"soft\" column index for each row\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for b in range(batch_size):\n",
    "        # We'll measure repeated distances in a (N, 2*N-1) boolean style, but in a soft sense\n",
    "        perm = col_indices[b]  # shape: (N,)\n",
    "        # For each pair (i, j), i < j, check the vector difference\n",
    "        # i-j, perm[i]-perm[j]\n",
    "        # We'll do a simple penalty if differences are close\n",
    "\n",
    "        # We can't do a direct discrete check, so let's do a \"soft collision\" measure:\n",
    "        pair_count = 0\n",
    "        collision_penalty = 0.0\n",
    "        for i in range(N):\n",
    "            for j in range(i+1, N):\n",
    "                rdiff = j - i\n",
    "                cdiff = perm[j] - perm[i]\n",
    "                # We want distinct (rdiff, cdiff) for every pair\n",
    "                # We'll measure closeness to other pairs\n",
    "                # This is O(N^2) which might be slow for large N\n",
    "                for k in range(N):\n",
    "                    for l in range(k+1, N):\n",
    "                        if (k, l) != (i, j):\n",
    "                            rdiff2 = l - k\n",
    "                            cdiff2 = col_indices[b,l] - col_indices[b,k]\n",
    "                            # If (rdiff, cdiff) is \"close\" to (rdiff2, cdiff2),\n",
    "                            # penalize\n",
    "                            dist = ((rdiff - rdiff2)**2 + (cdiff - cdiff2)**2)\n",
    "                            # We want dist > 0 ideally\n",
    "                            # If dist is near 0, penalize\n",
    "                            collision_penalty += torch.exp(-dist)\n",
    "                pair_count += 1\n",
    "\n",
    "        # Combine\n",
    "        total_loss += collision_penalty / (pair_count + 1e-6)\n",
    "\n",
    "    return total_loss / batch_size\n",
    "\n",
    "def stitch_arrays_with_nn(n, epochs=100, lr=1e-2, hidden_dim=128):\n",
    "    \"\"\"\n",
    "    Attempt to create an NxN Costas array by combining prime-based sub-arrays\n",
    "    and letting a neural net produce a (soft) permutation.\n",
    "    \"\"\"\n",
    "    # 1. Gather sub-arrays for prime factors\n",
    "    sub_arrays = get_subarrays_from_prime_factors(n)\n",
    "    # Flatten & concatenate them into a single feature vector\n",
    "    # Just one example of an encoding; many other ways possible.\n",
    "    feats = []\n",
    "    for arr in sub_arrays:\n",
    "        if len(arr) > 0:\n",
    "            # normalize by length\n",
    "            arr_norm = arr / (len(arr)+1)\n",
    "            feats.extend(list(arr_norm))\n",
    "        else:\n",
    "            feats.extend([0.0])  # placeholder if no array\n",
    "    input_vec = torch.tensor(feats, dtype=torch.float32).unsqueeze(0)  # shape (1, input_dim)\n",
    "    input_dim = input_vec.shape[1]\n",
    "\n",
    "    # 2. Initialize the neural net\n",
    "    model = StitcherNet(input_dim, hidden_dim, n)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 3. Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_vec)  # shape: (1, N, N)\n",
    "        loss = costas_loss(out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss = {loss.item():.4f}\")\n",
    "\n",
    "    # 4. Get final \"soft\" solution\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(input_vec)  # (1, N, N)\n",
    "        row_probs = torch.softmax(out, dim=2)  # (1, N, N)\n",
    "        # final integer columns\n",
    "        col_indices = row_probs[0].argmax(dim=1)  # shape: (N,)\n",
    "    return col_indices.cpu().numpy()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Running an Example\n",
    "# --------------------------------------------------------------------P-----\n",
    "if __name__ == \"__main__\":\n",
    "    N = 30  # Example composite number\n",
    "    # Stitch sub-arrays with a small neural net:\n",
    "    stitched_perm = stitch_arrays_with_nn(N, epochs=200, lr=5e-2, hidden_dim=64)\n",
    "    print(\"\\nNeural-Net-Stitched Permutation (0-based columns):\")\n",
    "    print(stitched_perm)\n",
    "\n",
    "    # Visualize the stitched result\n",
    "    visualize_costas_array(stitched_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def is_valid_costas(array):\n",
    "    \"\"\"\n",
    "    Check if the given array is a valid Costas array.\n",
    "\n",
    "    Parameters:\n",
    "    array (numpy.ndarray): A 1D or 2D representation of a Costas array.\n",
    "        - If 1D: An array representing the permutation of the columns.\n",
    "        - If 2D: A binary matrix with 1s representing the \"dots\" of the array.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the array is a valid Costas array, False otherwise.\n",
    "    \"\"\"\n",
    "    if array.ndim == 1:\n",
    "        # 1D permutation representation\n",
    "        N = len(array)\n",
    "        if len(set(array)) != N or np.any(array < 0) or np.any(array >= N):\n",
    "            return False  # Invalid permutation\n",
    "\n",
    "        # Convert to binary matrix for easier displacement checking\n",
    "        binary_matrix = np.zeros((N, N), dtype=np.int64)\n",
    "        for i in range(N):\n",
    "            binary_matrix[i, array[i]] = 1\n",
    "\n",
    "    elif array.ndim == 2:\n",
    "        # 2D binary matrix representation\n",
    "        binary_matrix = array\n",
    "        N = binary_matrix.shape[0]\n",
    "        if binary_matrix.shape[1] != N:\n",
    "            return False  # Must be square\n",
    "\n",
    "        # Check if each row and column has exactly one \"1\"\n",
    "        if not np.all(binary_matrix.sum(axis=0) == 1) or not np.all(binary_matrix.sum(axis=1) == 1):\n",
    "            return False\n",
    "    else:\n",
    "        return False  # Invalid input format\n",
    "\n",
    "    # Check displacement vectors for distinctness\n",
    "    positions = np.argwhere(binary_matrix == 1)  # Get row-column coordinates of dots\n",
    "    num_positions = len(positions)\n",
    "    displacements = set()\n",
    "\n",
    "    for i in range(num_positions):\n",
    "        for j in range(i + 1, num_positions):\n",
    "            r_diff = positions[j, 0] - positions[i, 0]\n",
    "            c_diff = positions[j, 1] - positions[i, 1]\n",
    "            displacement = (r_diff, c_diff)\n",
    "\n",
    "            if displacement in displacements:\n",
    "                return False  # Repeated displacement vector\n",
    "\n",
    "            displacements.add(displacement)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated using Welch method.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid_costas(stitched_perm), is_valid_costas(generate_costas_array(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
